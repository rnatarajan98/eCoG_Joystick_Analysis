{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58244c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is cuda? False\n"
     ]
    }
   ],
   "source": [
    "#Setup\n",
    "\n",
    "# Install Packages\n",
    "import sys\n",
    "!{sys.executable} -m pip install numpy --quiet\n",
    "!{sys.executable} -m pip install matplotlib --quiet\n",
    "!{sys.executable} -m pip install seaborn --quiet\n",
    "!{sys.executable} -m pip install sklearn --quiet\n",
    "!{sys.executable} -m pip install torch --quiet\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import os, requests\n",
    "from matplotlib import rcParams \n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import math\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "\n",
    "# Data Retrieval\n",
    "\n",
    "fname = 'joystick_track.npz'\n",
    "url = \"https://osf.io/6jncm/download\"\n",
    "\n",
    "print('Is cuda?', torch.cuda.is_available())\n",
    "\n",
    "if not os.path.isfile(fname):\n",
    "  try:\n",
    "    r = requests.get(url)\n",
    "  except requests.ConnectionError:\n",
    "    print(\"!!! Failed to download data !!!\")\n",
    "  else:\n",
    "    if r.status_code != requests.codes.ok:\n",
    "      print(\"!!! Failed to download data !!!\")\n",
    "    else:\n",
    "      with open(fname, \"wb\") as fid:\n",
    "        fid.write(r.content)\n",
    "# Import matplotlib and set styling\n",
    "rcParams['figure.figsize'] = [20, 4]\n",
    "rcParams['font.size'] =15\n",
    "rcParams['axes.spines.top'] = False\n",
    "rcParams['axes.spines.right'] = False\n",
    "rcParams['figure.autolayout'] = True\n",
    "\n",
    "colourmap_diverge = sns.diverging_palette(321, 172, s=100, n=100, center = \"light\", as_cmap=True)\n",
    "colourmap = sns.color_palette(\"rocket\", as_cmap=True)\n",
    "colourmap = sns.light_palette(\"#30887c\", as_cmap=True)\n",
    "colourmap_diverge.set_bad(\"black\", alpha=0)\n",
    "colourmap.set_bad(\"black\", alpha=0)\n",
    "\n",
    "# Data Loading\n",
    "alldat = np.load(fname, allow_pickle=True)['dat']\n",
    "\n",
    "# Select just one of the recordings here. This is subject 1, block 1.\n",
    "dat = alldat[0, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca011308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is cuda? False\n"
     ]
    }
   ],
   "source": [
    "print('Is cuda?', torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    !nvcc --version\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "torch.manual_seed(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bcf9a9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define normalisation of voltage channels\n",
    "\n",
    "Vmax =  max((max(x) for x in dat['V']))\n",
    "Vmin = min((min(x) for x in dat['V']))\n",
    "xmax = max(dat['cursorX'])\n",
    "xmin = min(dat['cursorX'])\n",
    "ymax = max(dat['cursorY'])\n",
    "ymin = min(dat['cursorY'])\n",
    "\n",
    "def Vnormalise(_V):\n",
    "    _V_norm = (_V - Vmin)/(Vmax - Vmin)\n",
    "    return _V_norm\n",
    "\n",
    "def normalise(_V):\n",
    "    _V_norm = (_V - min(_V))/(max(_V) - min(_V))\n",
    "    return _V_norm\n",
    "\n",
    "def Xnormalise(_x):\n",
    "    _x_norm = (_x - xmin)/(xmax - xmin)\n",
    "    return _x_norm\n",
    "    \n",
    "def Xdenormalise(_x):\n",
    "    _x_denorm = _x*(xmax - xmin) + xmin\n",
    "    return _x_denorm\n",
    "\n",
    "def Ynormalise(_y):\n",
    "    _y_norm = (_y - ymin)/(ymax - ymin)\n",
    "    return _y_norm\n",
    "    \n",
    "def Ydenormalise(_y):\n",
    "    _y_denorm = _y*(ymax - ymin) + ymin\n",
    "    return _y_denorm\n",
    "\n",
    "  \n",
    "def downsample(signal, factor):\n",
    "  nbins = math.floor(nt/factor)\n",
    "  signal_norm = np.zeros((nbins, 1))\n",
    "  for ibin in range(nbins):\n",
    "    binstart = ibin * 40\n",
    "    binend = binstart + 40\n",
    "    signal_norm[ibin, 0] = np.mean(signal[binstart:binend])\n",
    "\n",
    "  return signal_norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1cce860e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples 134360 number of channels 64\n",
      "V shape (134360, 64)\n",
      "cx, cy shape (134360, 1) (134360, 1)\n",
      "post normalisation:\n",
      "number of samples 134360 number of channels 64\n",
      "V shape (3359, 64)\n",
      "cx, cy shape (3359, 1) (3359, 1)\n"
     ]
    }
   ],
   "source": [
    "ds = True #downsample data?\n",
    "select_channels = False #Use correlated channels only?\n",
    "\n",
    "\n",
    "# Load patient 2\n",
    "dat = alldat[0, 2]\n",
    "corr_chan = sorted([5, 23, 17, 1, 25])\n",
    "\n",
    "V = dat['V']\n",
    "V = Vnormalise(V)\n",
    "nt, nchan = V.shape\n",
    "\n",
    "if select_channels:\n",
    "  V = V[:, corr_chan]\n",
    "\n",
    "cx = Xnormalise(dat['cursorX'].flatten()).reshape(-1,1)\n",
    "cy = Ynormalise(dat['cursorY'].flatten()).reshape(-1,1)\n",
    "\n",
    "print('number of samples', nt, 'number of channels', nchan)\n",
    "print('V shape', V.shape)\n",
    "print('cx, cy shape', cx.shape, cy.shape)\n",
    "\n",
    "factor = 40 #cursor trajectory updates every 40 samples, hardware limitation\n",
    "if downsample:\n",
    "  nbins = math.floor(nt/factor)\n",
    "\n",
    "  V_norm = np.zeros((nbins, nchan))\n",
    "  for c in range(nchan):\n",
    "    V_norm[:,c] = downsample(V[:,c], 40).flatten()\n",
    "  V = V_norm\n",
    "  cx = downsample(cx, 40)\n",
    "  cy = downsample(cy, 40)\n",
    "\n",
    "  print(\"post normalisation:\")\n",
    "  print('number of samples', nt, 'number of channels', nchan)\n",
    "  print('V shape', V.shape)\n",
    "  print('cx, cy shape', cx.shape, cy.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4531f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequences(input_sequences, output_sequence, n_steps_in, n_steps_out):\n",
    "    X, y = list(), list() # instantiate X and y\n",
    "    for i in range(len(input_sequences)):\n",
    "        # find the end of the input, output sequence\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out - 1\n",
    "        # check if we are beyond the dataset\n",
    "        if out_end_ix > len(input_sequences): break\n",
    "        # gather input and output of the pattern\n",
    "        seq_x, seq_y = input_sequences[i:end_ix], output_sequence[end_ix-1:out_end_ix, -1]\n",
    "        X.append(seq_x), y.append(seq_y)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "07212f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tensors(X, y, tt_ratio = 0.8, lookback = 200, lookahead = 25):\n",
    "    X_ss, y_ss = split_sequences(X, y, lookback, lookahead)\n",
    "\n",
    "    total_samples = len(X)\n",
    "    train_test_cutoff = round(tt_ratio* total_samples)\n",
    "\n",
    "    X_train = X_ss[:train_test_cutoff]\n",
    "    X_test = X_ss[train_test_cutoff:]\n",
    "\n",
    "    y_train = y_ss[:train_test_cutoff]\n",
    "    y_test = y_ss[train_test_cutoff:] \n",
    "\n",
    "    X_train_tensors = Variable(torch.Tensor(X_train))\n",
    "    X_test_tensors = Variable(torch.Tensor(X_test))\n",
    "\n",
    "    y_train_tensors = Variable(torch.Tensor(y_train))\n",
    "    y_test_tensors = Variable(torch.Tensor(y_test))\n",
    "\n",
    "    X_train_tensors_final = torch.reshape(X_train_tensors,   \n",
    "                                          (X_train_tensors.shape[0], lookback, \n",
    "                                           X_train_tensors.shape[2]))\n",
    "    X_test_tensors_final = torch.reshape(X_test_tensors,  \n",
    "                                         (X_test_tensors.shape[0], lookback, \n",
    "                                          X_test_tensors.shape[2])) \n",
    "\n",
    "    print(\"Training Shape:\", X_train_tensors_final.shape, y_train_tensors.shape)\n",
    "    print(\"Testing Shape:\", X_test_tensors_final.shape, y_test_tensors.shape) \n",
    "    print(\"Test/Train cutoff\", train_test_cutoff)\n",
    "    print(\"Total data points\", total_samples)\n",
    "    \n",
    "    return X_train_tensors_final, y_train_tensors, X_test_tensors_final, y_test_tensors\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5ad268dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes # output size\n",
    "        self.num_layers = num_layers # number of recurrent layers in the lstm\n",
    "        self.input_size = input_size # input size\n",
    "        self.hidden_size = hidden_size # neurons in each lstm layer\n",
    "        # LSTM model\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
    "                            num_layers=num_layers, batch_first=True, dropout=0.2) # lstm\n",
    "        self.fc_1 =  nn.Linear(hidden_size, 100) # fully connected \n",
    "        self.fc_2 = nn.Linear(100, num_classes) # fully connected last layer\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        # hidden state\n",
    "        h_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size))\n",
    "        # cell state\n",
    "        c_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size))\n",
    "        # propagate input through LSTM\n",
    "        output, (hn, cn) = self.lstm(x, (h_0, c_0)) # (input, hidden, and internal state)\n",
    "        hn = hn.view(-1, self.hidden_size) # reshaping the data for Dense layer next\n",
    "        out = self.relu(hn)\n",
    "        out = self.fc_1(out) # first dense\n",
    "        out = self.relu(out) # relu\n",
    "        out = self.fc_2(out) # final output\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dd619e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, lstm, optimiser, loss_fn, X_train, y_train,\n",
    "                  X_test, y_test):\n",
    "    test_losses = []\n",
    "    train_losses = []\n",
    "    for epoch in range(n_epochs):\n",
    "        lstm.train()\n",
    "        outputs = lstm.forward(X_train) # forward pass\n",
    "        optimiser.zero_grad() # calculate the gradient, manually setting to 0\n",
    "        # obtain the loss function\n",
    "        loss = loss_fn(outputs, y_train)\n",
    "        loss.backward() # calculates the loss of the loss function\n",
    "        optimiser.step() # improve from loss, i.e backprop\n",
    "        # test loss\n",
    "        lstm.eval()\n",
    "        test_preds = lstm(X_test)\n",
    "        test_loss = loss_fn(test_preds, y_test)\n",
    "        train_losses.append(loss.item())\n",
    "        test_losses.append(test_loss.item())\n",
    "        if epoch % 100 == 0 or (epoch < 50 and epoch % 10 == 0):\n",
    "            print(\"Epoch: %d, train loss: %1.5f, test loss: %1.5f\" % (epoch, \n",
    "                                                                      loss.item(), \n",
    "                                                                      test_loss.item())) \n",
    "    return train_losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "37ae15df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define plotting functions\n",
    "def predict(model, inputs, targets, tt_ratio, test=False):\n",
    "  df_X_ss = inputs\n",
    "  df_y_mm = targets\n",
    "  # split the sequence\n",
    "  X_ss, y_ss = split_sequences(inputs, targets, lookback, lookahead)\n",
    "\n",
    "  # converting to tensors\n",
    "  df_X_ss = Variable(torch.Tensor(X_ss))\n",
    "  df_y_mm = Variable(torch.Tensor(y_ss))\n",
    "  # reshaping the dataset\n",
    "  df_X_ss = torch.reshape(df_X_ss, (df_X_ss.shape[0], lookback, df_X_ss.shape[2]))\n",
    "\n",
    "  train_predict = model(df_X_ss) # forward pass\n",
    "  data_predict = train_predict.cpu().data.numpy() # numpy conversion\n",
    "  dataY_plot = df_y_mm.cpu().data.numpy()\n",
    "\n",
    "\n",
    "  true, preds = [], []\n",
    "  for i in range(len(dataY_plot)):\n",
    "      true.append(dataY_plot[i][0])\n",
    "  for i in range(len(data_predict)):\n",
    "      preds.append(data_predict[i][0])\n",
    "\n",
    "  total_samples = len(true)\n",
    "  train_test_cutoff = round(tt_ratio* total_samples)\n",
    "\n",
    "  print(\"Predicted trajectory length:\", len(true))\n",
    "  if test:\n",
    "    true = true[train_test_cutoff:]\n",
    "    preds = preds[train_test_cutoff:]\n",
    "    print(\"Predicted trajectory TEST length:\", len(true))\n",
    "  \n",
    "  \n",
    "  return true, preds\n",
    "\n",
    "def plot_prediction(true, preds, tt_ratio):\n",
    "\n",
    "  total_samples = len(true)\n",
    "  train_test_cutoff = round(tt_ratio* total_samples)\n",
    "\n",
    "  plt.figure(figsize=(20,6)) #plotting\n",
    "  plt.subplot(1, 2, 1)\n",
    "  plt.plot(true, label='Actual Data') # actual plot\n",
    "  plt.plot(preds, label='Predicted Data') # predicted plot\n",
    "  plt.axvline(x=train_test_cutoff, c='r', linestyle='--') # size of the training set\n",
    "  plt.title('Time-Series Prediction')\n",
    "  plt.legend()\n",
    "\n",
    "  plt.subplot(1, 2, 2)\n",
    "  plt.plot(true, label='Actual Data') # actual plot\n",
    "  plt.plot(preds, label='Predicted Data') # predicted plot\n",
    "  plt.title('Time-Series Prediction')\n",
    "  plt.legend()\n",
    "  plt.savefig(\"whole_plot.png\", dpi=300)\n",
    "  plt.xlim(left = train_test_cutoff - train_test_cutoff*0/1)\n",
    "  plt.axvline(x=train_test_cutoff, c='r', linestyle='--') # size of the training set\n",
    "  plt.show() \n",
    "\n",
    "  print(\"test/train boundary:\", train_test_cutoff)\n",
    "  print(\"test/train proportion:\", train_test_cutoff/total_samples)\n",
    "  print(\"train length:\", total_samples - train_test_cutoff)\n",
    "  rms_test = rms(np.array(true), np.array(preds))\n",
    "  print(rms_test)\n",
    "\n",
    "\n",
    "def plot_losses(train_loss, test_loss):\n",
    "  plt.plot(train_loss, label=\"Train Losses\")\n",
    "  plt.plot(test_loss, label=\"Test Losses\")\n",
    "  plt.legend\n",
    "\n",
    "def bin_trajectory(x, y, nbins):\n",
    "  bin_x = np.array_split(x, nbins)\n",
    "  bin_y = np.array_split(y, nbins)\n",
    "  bin_traj = []\n",
    "  \n",
    "  for i in range(len(bin_x)):\n",
    "    traj_chunk = np.asarray([bin_x[i], bin_y[i]])\n",
    "    bin_traj.append(traj_chunk)\n",
    "\n",
    "  binsize = traj_chunk.shape[1]\n",
    "  return bin_traj, binsize\n",
    "\n",
    "def plot_trajectories(true_x, true_y, preds_x, preds_y, nbins = 5, shadow = False):\n",
    "  true_traj_bin, binsize = bin_trajectory(true_x, true_y, nbins=nbins)\n",
    "  pred_traj_bin, binsize = bin_trajectory(preds_x, preds_y, nbins=nbins)\n",
    "\n",
    "  print(int(binsize/4))\n",
    "\n",
    "  h = 3\n",
    "  plt.figure(figsize = (h*nbins, h))\n",
    "  for i, b in enumerate(range(nbins)):\n",
    "    plt.subplot(1, nbins, b+1)\n",
    "    if shadow:\n",
    "      for j in [-1, 1]:\n",
    "        try:\n",
    "          plt.plot(true_traj_bin[i+j][0][int(binsize/4):], true_traj_bin[i+j][1][int(binsize/4):], color='gainsboro')\n",
    "          plt.plot(pred_traj_bin[i+j][0][:int(binsize/4)], pred_traj_bin[i+j][1][:int(binsize/4)], color='gainsboro')\n",
    "        except:\n",
    "          pass\n",
    "      \n",
    "    plt.plot(true_traj_bin[i][0], true_traj_bin[i][1], label=\"true trajectory\")\n",
    "    plt.plot(pred_traj_bin[i][0], pred_traj_bin[i][1], label=\"predicted trajectory\")\n",
    "\n",
    "  plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc2d2d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define common metric between models\n",
    "def rms(truth, prediction):\n",
    "    _diff = truth - prediction\n",
    "    _diff_flat = _diff.flatten()\n",
    "    _rms = np.sqrt(np.mean(_diff_flat**2))\n",
    "    return _rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8f755cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing parameters\n",
    "train_test_proportion = 0.8\n",
    "lookback, lookahead = 400, 200 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "41fd90c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Shape: torch.Size([2687, 200, 64]) torch.Size([2687, 25])\n",
      "Testing Shape: torch.Size([449, 200, 64]) torch.Size([449, 25])\n",
      "Test/Train cutoff 2687\n",
      "Total data points 3359\n",
      "Epoch: 0, train loss: 0.48003, test loss: 0.61849\n",
      "Epoch: 10, train loss: 0.31547, test loss: 0.40488\n",
      "Epoch: 20, train loss: 0.18048, test loss: 0.21172\n",
      "Epoch: 30, train loss: 0.11756, test loss: 0.09497\n",
      "Epoch: 40, train loss: 0.10418, test loss: 0.06177\n",
      "Epoch: 100, train loss: 0.09929, test loss: 0.07215\n",
      "Epoch: 200, train loss: 0.09491, test loss: 0.06335\n",
      "Epoch: 300, train loss: 0.06643, test loss: 0.06373\n",
      "Epoch: 400, train loss: 0.05817, test loss: 0.06910\n",
      "Epoch: 500, train loss: 0.05385, test loss: 0.07788\n",
      "Epoch: 600, train loss: 0.04935, test loss: 0.07798\n",
      "Epoch: 700, train loss: 0.04418, test loss: 0.08029\n",
      "Epoch: 800, train loss: 0.04130, test loss: 0.09319\n",
      "Epoch: 900, train loss: 0.03516, test loss: 0.08489\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "plot_prediction() takes 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 31>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m optimiser \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(lstm_x\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlearning_rate) \n\u001b[0;32m     22\u001b[0m train_loss, test_loss \u001b[38;5;241m=\u001b[39m training_loop(n_epochs\u001b[38;5;241m=\u001b[39mn_epochs,\n\u001b[0;32m     23\u001b[0m               lstm\u001b[38;5;241m=\u001b[39mlstm_x,\n\u001b[0;32m     24\u001b[0m               optimiser\u001b[38;5;241m=\u001b[39moptimiser,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     28\u001b[0m               X_test\u001b[38;5;241m=\u001b[39mX_test_tensors_final,\n\u001b[0;32m     29\u001b[0m               y_test\u001b[38;5;241m=\u001b[39my_test_tensors)\n\u001b[1;32m---> 31\u001b[0m \u001b[43mplot_prediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlstm_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mV\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_train_proportion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m plot_losses(train_loss, test_loss)\n",
      "\u001b[1;31mTypeError\u001b[0m: plot_prediction() takes 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "# model architecture parameters\n",
    "input_size = nchan # number of features\n",
    "hidden_size = 10 # number of features in hidden state\n",
    "num_layers = 1 # number of stacked lstm layers\n",
    "\n",
    "num_classes = lookahead # number of output classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ccfbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning hyperparameters\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "n_epochs = 1000 # 2000 epochs\n",
    "learning_rate = 0.001 # 0.005 lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1ef25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate tensors for x model\n",
    "X_train_tensors_final, y_train_tensors, X_test_tensors_final, y_test_tensors = generate_tensors(V, cx, train_test_proportion, lookback, lookahead)\n",
    "\n",
    "# instantiate x model\n",
    "lstm_x = LSTM(num_classes, \n",
    "              input_size, \n",
    "              hidden_size, \n",
    "              num_layers)\n",
    "\n",
    "# define training methods\n",
    "loss_fn = torch.nn.MSELoss()    # mean-squared error for regression\n",
    "optimiser = torch.optim.Adam(lstm_x.parameters(), lr=learning_rate) \n",
    "\n",
    "# train model\n",
    "train_loss_x, test_loss_x = training_loop(n_epochs=n_epochs,\n",
    "              lstm=lstm_x,\n",
    "              optimiser=optimiser,\n",
    "              loss_fn=loss_fn,\n",
    "              X_train=X_train_tensors_final,\n",
    "              y_train=y_train_tensors,\n",
    "              X_test=X_test_tensors_final,\n",
    "              y_test=y_test_tensors)\n",
    "\n",
    "# generate final prediction\n",
    "true_x, preds_x = predict(lstm_x, V, cx, train_test_proportion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4536b00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate tensors for y model\n",
    "X_train_tensors_final, y_train_tensors, X_test_tensors_final, y_test_tensors = generate_tensors(V, cy, train_test_proportion, lookback, lookahead)\n",
    "\n",
    "# instantiate model\n",
    "lstm_y = LSTM(num_classes, \n",
    "              input_size, \n",
    "              hidden_size, \n",
    "              num_layers)\n",
    "\n",
    "# define training methods\n",
    "loss_fn = torch.nn.MSELoss()    # mean-squared error for regression\n",
    "optimiser = torch.optim.Adam(lstm_y.parameters(), lr=learning_rate) \n",
    "\n",
    "# train model\n",
    "train_loss_y, test_loss_y = training_loop(n_epochs=n_epochs,\n",
    "              lstm=lstm_y,\n",
    "              optimiser=optimiser,\n",
    "              loss_fn=loss_fn,\n",
    "              X_train=X_train_tensors_final,\n",
    "              y_train=y_train_tensors,\n",
    "              X_test=X_test_tensors_final,\n",
    "              y_test=y_test_tensors)\n",
    "\n",
    "# generate final prediction\n",
    "true_y, preds_y = predict(lstm_y, V, cy, train_test_proportion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dbf2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prediction(true_x, preds_x, train_test_proportion)\n",
    "plot_losses(train_loss_x, test_loss_x)\n",
    "\n",
    "plot_prediction(true_y, preds_y, train_test_proportion)\n",
    "plot_losses(train_loss_y, test_loss_y)\n",
    "\n",
    "true_x_test, preds_x_test = predict(lstm_x, V, cx, train_test_proportion, test=True)\n",
    "true_y_test, preds_y_test = predict(lstm_y, V, cy, train_test_proportion, test=True)\n",
    "plot_trajectories(true_x_test, true_y_test, preds_x_test, preds_y_test, nbins=5, shadow=True)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
